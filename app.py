# -*- coding: utf-8 -*-

import streamlit as st
import pandas as pd
import requests
from Bio import Entrez
from datetime import datetime
import time
import re
from typing import Dict, List, Optional, Tuple
import json
from bs4 import BeautifulSoup
from fake_useragent import UserAgent
import urllib.parse

# ==================== é…ç½®ä¸åˆå§‹åŒ– ====================
st.set_page_config(
    page_title="ç»†èƒç³»æ„å»ºæ™ºèƒ½è¯„ä¼°ç³»ç»Ÿ",
    page_icon="ğŸ”¬",
    layout="wide",
    initial_sidebar_state="expanded"
)

# å®‰å…¨å¯†é’¥é…ç½®
try:
    NCBI_EMAIL = st.secrets["NCBI_EMAIL"]
    NCBI_API_KEY = st.secrets.get("NCBI_API_KEY", "")
    APP_PASSWORD = st.secrets.get("APP_PASSWORD", "")
except Exception:
    st.error("âš ï¸ è¯·å…ˆé…ç½® Secretsï¼ˆNCBI_EMAIL ç­‰ï¼‰")
    st.stop()

# å¯†ç ä¿æŠ¤
if APP_PASSWORD:
    if 'authenticated' not in st.session_state:
        st.session_state.authenticated = False
    if not st.session_state.authenticated:
        pwd = st.text_input("ğŸ”’ è¯·è¾“å…¥è®¿é—®å¯†ç ", type="password")
        if pwd == APP_PASSWORD:
            st.session_state.authenticated = True
            st.rerun()
        elif pwd:
            st.error("å¯†ç é”™è¯¯")
        st.stop()

# åˆå§‹åŒ– session state
if 'analysis_results' not in st.session_state:
    st.session_state.analysis_results = None
if 'search_history' not in st.session_state:
    st.session_state.search_history = []

# ==================== æ ¸å¿ƒæ•°æ®è·å–æ¨¡å— ====================

class AddgeneScraper:
    """ä¼˜åŒ–çš„ Addgene è´¨ç²’çˆ¬å–å™¨"""
    
    def __init__(self):
        self.base_url = "https://www.addgene.org"
        self.ua = UserAgent()
        self.session = requests.Session()
        self.session.headers.update({
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
            'Accept-Language': 'en-US,en;q=0.5',
        })
    
    @st.cache_data(ttl=86400, show_spinner=False)
    def search_plasmids(_self, gene_symbol: str, max_results: int = 5) -> List[Dict]:
        """æ·±åº¦çˆ¬å– Addgene è´¨ç²’ä¿¡æ¯"""
        try:
            query = urllib.parse.quote(f"{gene_symbol}")
            search_url = f"{_self.base_url}/search/?q={query}&type=plasmid"
            headers = {'User-Agent': _self.ua.random}
            time.sleep(1)
            
            response = _self.session.get(search_url, headers=headers, timeout=15)
            response.raise_for_status()
            soup = BeautifulSoup(response.text, 'lxml')
            plasmids = []
            
            # å¤šç­–ç•¥è§£æ
            result_items = (soup.find_all('article', class_='addgene-search-result') or 
                           soup.find_all('div', class_='search-result-item') or
                           soup.select('.plasmid-item'))
            
            if not result_items:
                result_items = soup.select('[data-testid="plasmid-card"]')
            
            for item in result_items[:max_results]:
                try:
                    plasmid_data = _self._parse_plasmid_card(item, gene_symbol)
                    if plasmid_data:
                        plasmids.append(plasmid_data)
                except Exception:
                    continue
            
            # å¤‡ç”¨æ–¹æ¡ˆï¼šç›´æ¥è®¿é—®åŸºå› é¡µé¢
            if not plasmids:
                plasmids = _self._search_by_gene_page(gene_symbol)
            
            return plasmids
            
        except Exception as e:
            st.error(f"Addgene çˆ¬å–é”™è¯¯: {str(e)}")
            return []
    
    def _parse_plasmid_card(self, card, gene_symbol: str) -> Optional[Dict]:
        """è§£æå•ä¸ªè´¨ç²’å¡ç‰‡"""
        try:
            link_tag = card.find('a', href=re.compile(r'/\d{5,6}/')) or card.find('a', href=True)
            if not link_tag:
                return None
            
            href = link_tag.get('href', '')
            plasmid_id_match = re.search(r'/(\d{5,6})/', href)
            if not plasmid_id_match:
                return None
            
            plasmid_id = plasmid_id_match.group(1)
            full_url = f"{self.base_url}{href}" if href.startswith('/') else href
            
            name_tag = card.find('h3') or card.find('h2') or card.find('a', class_='title')
            name = name_tag.get_text(strip=True) if name_tag else "Unknown"
            
            # ç›¸å…³æ€§æ£€æŸ¥
            if gene_symbol.lower() not in name.lower():
                desc = card.get_text().lower()
                if gene_symbol.lower() not in desc:
                    return None
            
            metadata = {
                'plasmid_id': plasmid_id,
                'name': name,
                'url': full_url,
                'insert_gene': gene_symbol,
            }
            
            # æå–è¡¨è¾¾ç³»ç»Ÿ
            expr_match = re.search(r'(Lenti|Retro|AAV|Mammalian|Bacterial|Insect)', 
                                  card.get_text(), re.I)
            if expr_match:
                metadata['expression_system'] = expr_match.group(1)
            
            # æå–è§å…‰æ ‡è®°
            fluo_match = re.search(r'(GFP|RFP|mCherry|YFP|Luciferase|Flag|HA)', 
                                  card.get_text(), re.I)
            if fluo_match:
                metadata['tag'] = fluo_match.group(1)
            
            return metadata
            
        except Exception:
            return None
    
    def _search_by_gene_page(self, gene_symbol: str) -> List[Dict]:
        """é€šè¿‡åŸºå› ä¸“ç”¨é¡µé¢æœç´¢"""
        try:
            gene_url = f"{self.base_url}/browse/gene/{gene_symbol}/"
            headers = {'User-Agent': self.ua.random}
            response = self.session.get(gene_url, headers=headers, timeout=10)
            
            if response.status_code != 200:
                return []
            
            soup = BeautifulSoup(response.text, 'lxml')
            plasmids = []
            seen_ids = set()
            
            links = soup.find_all('a', href=re.compile(r'/\d{5,6}/'))
            for link in links[:5]:
                href = link.get('href', '')
                match = re.search(r'/(\d{5,6})/', href)
                if match:
                    pid = match.group(1)
                    if pid not in seen_ids:
                        seen_ids.add(pid)
                        plasmids.append({
                            'plasmid_id': pid,
                            'name': link.get_text(strip=True) or f"{gene_symbol} related",
                            'url': f"{self.base_url}/{pid}/",
                            'insert_gene': gene_symbol,
                            'source': 'Gene page'
                        })
            return plasmids
        except Exception:
            return []


class HumanAtlasScraper:
    """Human Protein Atlas æŠ—ä½“ä¿¡æ¯çˆ¬å–"""
    
    def __init__(self):
        self.base_url = "https://www.proteinatlas.org"
        self.ua = UserAgent()
        self.session = requests.Session()
    
    @st.cache_data(ttl=86400, show_spinner=False)
    def get_antibodies(_self, gene_symbol: str) -> List[Dict]:
        """è·å–ç»éªŒè¯çš„æŠ—ä½“åˆ—è¡¨"""
        try:
            search_url = f"{_self.base_url}/{gene_symbol}"
            time.sleep(1)
            headers = {'User-Agent': _self.ua.random}
            
            response = _self.session.get(search_url, headers=headers, timeout=15)
            if response.status_code != 200:
                return []
            
            soup = BeautifulSoup(response.text, 'lxml')
            antibodies = []
            
            # ç­–ç•¥1ï¼šæŸ¥æ‰¾æŠ—ä½“è¡¨æ ¼
            ab_links = soup.find_all('a', href=re.compile(r'/ENSG\d+-\w+/antibody'))
            
            for link in ab_links[:5]:
                try:
                    ab_url = link.get('href')
                    if ab_url.startswith('/'):
                        ab_url = f"{_self.base_url}{ab_url}"
                    
                    ab_info = _self._parse_antibody_page(ab_url, gene_symbol)
                    if ab_info:
                        antibodies.append(ab_info)
                except Exception:
                    continue
            
            # ç­–ç•¥2ï¼šè§£æé¡µé¢ä¸Šçš„æŠ—ä½“åˆ—è¡¨
            if not antibodies:
                rows = soup.find_all('tr', class_=lambda x: x and 'antibody' in x.lower())
                for row in rows[:5]:
                    cells = row.find_all('td')
                    if len(cells) >= 3:
                        ab_id = cells[0].get_text(strip=True)
                        apps = _self._parse_applications(cells[1].get_text())
                        reliability = cells[2].get_text(strip=True)
                        
                        antibodies.append({
                            'gene': gene_symbol,
                            'antibody_id': ab_id,
                            'source': 'HPA',
                            'applications': apps,
                            'reliability': reliability,
                            'vendor': 'Atlas Antibodies',
                            'link': search_url
                        })
            
            return antibodies
            
        except Exception as e:
            st.warning(f"Human Atlas æŸ¥è¯¢å¤±è´¥: {e}")
            return []
    
    def _parse_antibody_page(self, url: str, gene_symbol: str) -> Optional[Dict]:
        """è§£æå•ä¸ªæŠ—ä½“é¡µé¢"""
        try:
            time.sleep(0.5)
            headers = {'User-Agent': self.ua.random}
            response = self.session.get(url, headers=headers, timeout=10)
            soup = BeautifulSoup(response.text, 'lxml')
            
            # æå–æŠ—ä½“ID
            ab_id_match = re.search(r'(HPA\d{6}|CAB\d{6})', url)
            ab_id = ab_id_match.group(1) if ab_id_match else "Unknown"
            
            # æå–åº”ç”¨
            app_text = soup.get_text()
            applications = self._parse_applications(app_text)
            
            # å¯é æ€§åˆ¤æ–­
            reliability = "Enhanced" if "enhanced" in app_text.lower() else \
                         "Supported" if "supported" in app_text.lower() else "Uncertain"
            
            return {
                'gene': gene_symbol,
                'antibody_id': ab_id,
                'source': 'HPA',
                'applications': applications,
                'reliability': reliability,
                'vendor': 'Atlas Antibodies',
                'link': url
            }
        except Exception:
            return None
    
    def _parse_applications(self, text: str) -> str:
        """è§£æåº”ç”¨ç±»å‹"""
        apps = []
        text_lower = text.lower()
        app_map = {
            'western blot': 'WB', 'wb': 'WB',
            'immunohistochemistry': 'IHC', 'ihc': 'IHC',
            'immunofluorescence': 'IF', 'if': 'IF',
            'icc-if': 'ICC-IF', 'flow cytometry': 'FACS', 'facs': 'FACS'
        }
        for key, value in app_map.items():
            if key in text_lower:
                apps.append(value)
        return ', '.join(list(set(apps))) if apps else 'æœªæ ‡æ³¨'


class BioDataFetcher:
    """ç”Ÿç‰©æ•°æ®è·å–ä¸»ç±»"""
    
    def __init__(self, email: str, api_key: str = ""):
        Entrez.email = email
        if api_key:
            Entrez.api_key = api_key
        self.uniprot_base = "https://rest.uniprot.org/uniprotkb/search.json"
        self.headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'}
        self.addgene_scraper = AddgeneScraper()
        self.hpa_scraper = HumanAtlasScraper()
    
    def get_ncbi_gene_info(self, gene_symbol: str, species: str) -> Dict:
        """è·å– NCBI Gene ä¿¡æ¯"""
        try:
            term = f"{gene_symbol}[Gene Name] AND {species}[Organism]"
            handle = Entrez.esearch(db="gene", term=term, retmax=1)
            record = Entrez.read(handle)
            handle.close()
            
            if not record["IdList"]:
                return {"status": "not_found", "error": f"æœªæ‰¾åˆ° {gene_symbol} ({species})"}
            
            gene_id = record["IdList"][0]
            handle = Entrez.efetch(db="gene", id=gene_id, rettype="xml")
            gene_data = Entrez.read(handle)
            handle.close()
            
            gene_entry = gene_data[0]
            summary = gene_entry.get("Entrezgene_summary", "")
            
            # è‡´æ­»æ€§åˆ†æ
            lethal_keywords = ["essential", "lethal", "required for cell viability", 
                             "knockout mice die", "embryonic lethal"]
            phenotype = "éå¿…éœ€"
            if any(kw in summary.lower() for kw in lethal_keywords):
                phenotype = "å¿…éœ€ï¼ˆæ½œåœ¨è‡´æ­»é£é™©ï¼‰"
            
            return {
                "gene_id": gene_id,
                "symbol": gene_symbol,
                "species": species,
                "description": summary[:500] if summary else "æ— æè¿°",
                "phenotype": phenotype,
                "chromosome": gene_entry.get("Entrezgene_location", [{}])[0].get("Gene-location", {}).get("Gene-location_chromosome", "N/A"),
                "status": "success"
            }
        except Exception as e:
            return {"status": "error", "error": str(e)}
    
    def get_uniprot_info(self, gene_symbol: str, species: str) -> Dict:
        """è·å– UniProt è›‹ç™½ä¿¡æ¯"""
        try:
            species_map = {"Homo sapiens": "human", "Mus musculus": "mouse", "Rattus norvegicus": "rat"}
            org = species_map.get(species, species.lower())
            
            query = f"gene:{gene_symbol}+organism:{org}"
            params = {
                "query": query,
                "fields": "accession,gene_names,length,cc_subcellular_location,sequence",
                "format": "json",
                "size": 1
            }
            
            response = requests.get(self.uniprot_base, params=params, headers=self.headers, timeout=10)
            data = response.json()
            
            if not data.get("results"):
                return {"status": "not_found", "error": f"UniProt æœªæ‰¾åˆ° {gene_symbol}"}
            
            protein = data["results"][0]
            accession = protein.get("primaryAccession", "")
            seq_length = protein.get("sequence", {}).get("length", 0)
            
            # æå–äºšç»†èƒå®šä½
            loc_text = ""
            comments = protein.get("comments", [])
            for comment in comments:
                if comment.get("commentType") == "SUBCELLULAR LOCATION":
                    locations = comment.get("subcellularLocations", [])
                    locs = [loc.get("location", {}).get("value", "") for loc in locations]
                    loc_text = "; ".join([l for l in locs if l])
            
            cds_length = seq_length * 3 if seq_length else 0
            
            return {
                "uniprot_id": accession,
                "protein_length": seq_length,
                "cds_length_bp": cds_length,
                "subcellular_location": loc_text or "æœªæ ‡æ³¨",
                "status": "success"
            }
        except Exception as e:
            return {"status": "error", "error": str(e)}
    
    def search_pubmed_construct(self, gene_symbol: str, cell_line: Optional[str] = None, 
                              construct_type: Optional[str] = None) -> Tuple[List[Dict], int]:
        """æ£€ç´¢ PubMed ç»†èƒç³»æ„å»ºæ–‡çŒ®"""
        try:
            base_query = f'{gene_symbol}[Title/Abstract]'
            
            if cell_line:
                query = f'{base_query} AND {cell_line}[Title/Abstract]'
            else:
                type_map = {
                    "overexpression": "overexpression OR over-expression OR ectopic",
                    "knockdown": "knockdown OR siRNA OR shRNA",
                    "knockout": "knockout OR CRISPR OR knock-out"
                }
                if construct_type:
                    query = f'{base_query} AND ({type_map.get(construct_type, construct_type)})'
                else:
                    query = base_query
            
            query += ' AND (cell line OR cell-line)'
            
            handle = Entrez.esearch(db="pubmed", term=query, retmax=100, sort="relevance")
            record = Entrez.read(handle)
            handle.close()
            
            pmids = record["IdList"]
            total_count = len(pmids)
            
            if not pmids:
                return [], 0
            
            fetch_ids = pmids[:10]
            handle = Entrez.efetch(db="pubmed", id=fetch_ids, rettype="abstract", retmode="xml")
            articles = Entrez.read(handle)
            handle.close()
            
            results = []
            for article in articles.get("PubmedArticle", []):
                try:
                    medline = article["MedlineCitation"]
                    article_data = medline["Article"]
                    title = article_data.get("ArticleTitle", "N/A")
                    pmid = medline.get("PMID", "N/A")
                    
                    abstract = ""
                    if "Abstract" in article_data and "AbstractText" in article_data["Abstract"]:
                        abstract = str(article_data["Abstract"]["AbstractText"])
                    
                    methods = []
                    method_keywords = ["lentiviral", "transfection", "electroporation", 
                                     "transduction", "lipofectamine", "infection"]
                    for kw in method_keywords:
                        if kw in abstract.lower():
                            methods.append(kw)
                    
                    results.append({
                        "pmid": str(pmid),
                        "title": title,
                        "methods": ", ".join(methods) if methods else "æœªæ˜ç¡®æåŠ",
                        "abstract_snippet": abstract[:200] + "..." if len(abstract) > 200 else abstract
                    })
                except Exception:
                    continue
            
            return results, total_count
        except Exception as e:
            st.error(f"PubMed æ£€ç´¢é”™è¯¯: {e}")
            return [], 0


class ConstructAnalyzer:
    """ç»†èƒç³»æ„å»ºåˆ†æä¸»ç±»"""
    
    def __init__(self):
        self.fetcher = BioDataFetcher(NCBI_EMAIL, NCBI_API_KEY)
    
    def analyze_gene(self, gene_symbol: str, species: str, 
                    cell_line: Optional[str] = None, 
                    cell_species: Optional[str] = None) -> Dict:
        """æ‰§è¡Œå®Œæ•´åˆ†ææµç¨‹"""
        
        with st.spinner(f"ğŸ” æ­£åœ¨æ·±åº¦åˆ†æ {gene_symbol}..."):
            
            # 1. NCBI Gene
            st.text("æ£€ç´¢ NCBI Gene...")
            ncbi_info = self.fetcher.get_ncbi_gene_info(gene_symbol, species)
            time.sleep(0.5)
            
            # 2. UniProt
            st.text("æ£€ç´¢ UniProt...")
            uniprot_info = self.fetcher.get_uniprot_info(gene_symbol, species)
            time.sleep(0.5)
            
            # 3. Addgeneï¼ˆä¼˜åŒ–çˆ¬å–ï¼‰
            st.text("æ·±åº¦æ£€ç´¢ Addgene...")
            addgene_plasmids = self.fetcher.addgene_scraper.search_plasmids(gene_symbol)
            time.sleep(0.5)
            
            # 4. HPA æŠ—ä½“ï¼ˆä¼˜åŒ–çˆ¬å–ï¼Œä»…äººç±»ï¼‰
            antibodies = []
            if species == "Homo sapiens":
                st.text("æ£€ç´¢ Human Protein Atlas...")
                antibodies = self.fetcher.hpa_scraper.get_antibodies(gene_symbol)
            
            # 5. æ…¢ç—…æ¯’è¯„ä¼°
            lentiviral = self._assess_lentiviral(ncbi_info, uniprot_info, addgene_plasmids)
            
            # 6. æ–‡çŒ®æ£€ç´¢
            st.text("æ£€ç´¢ç»†èƒç³»æ„å»ºæ–‡çŒ®...")
            literature = self._search_all_constructs(gene_symbol, cell_line)
            
            # æ•´åˆç»“æœ
            result = {
                "input_info": {
                    "gene_symbol": gene_symbol,
                    "species": species,
                    "cell_line": cell_line or "æœªæŒ‡å®š",
                    "cell_species": cell_species or "æœªæŒ‡å®š",
                    "analysis_date": datetime.now().strftime("%Y-%m-%d %H:%M")
                },
                "gene_function": ncbi_info,
                "protein_data": uniprot_info,
                "addgene_plasmids": addgene_plasmids,
                "antibodies": antibodies,
                "lentiviral_assessment": lentiviral,
                "cell_line_constructs": literature,
                "database_record": self._format_database_record(
                    gene_symbol, species, cell_line, ncbi_info, uniprot_info, 
                    lentiviral, literature, addgene_plasmids, antibodies
                )
            }
            
            return result
    
   def _assess_lentiviral(self, ncbi_info: Dict, uniprot_info: Dict, plasmids: List) -> Dict:
    """è¯„ä¼°æ…¢ç—…æ¯’é€‚ç”¨æ€§"""
    warnings = []
    recommendations = []
    score = 100  # åˆå§‹æ»¡åˆ†
    cds_len = uniprot_info.get("cds_length_bp", 0)
    
    # è‡´æ­»æ€§åˆ¤æ–­
    if ncbi_info.get("phenotype") == "å¿…éœ€ï¼ˆæ½œåœ¨è‡´æ­»é£é™©ï¼‰":
        warnings.append("âš ï¸ å¿…éœ€åŸºå› ï¼šå»ºè®®ä½¿ç”¨è¯±å¯¼å‹ç³»ç»Ÿï¼ˆTet-on/offï¼‰")
        score -= 50
    
    # åºåˆ—é•¿åº¦åˆ¤æ–­
    if cds_len > 9000:
        warnings.append(f"âš ï¸ CDS {cds_len}bp æ¥è¿‘åŒ…è£…æé™ï¼ˆ10kbï¼‰ï¼ŒåŒ…è£…æ•ˆç‡å¯èƒ½é™ä½")
        score -= 20
    elif cds_len > 12000:
        warnings.append(f"âŒ CDS {cds_len}bp è¶…å‡ºæ…¢ç—…æ¯’åŒ…è£…èƒ½åŠ›")
        score -= 80
    
    # Addgeneèµ„æº
    if plasmids:
        recommendations.append(f"âœ… Addgene æä¾› {len(plasmids)} ä¸ªè´¨ç²’")
    else:
        recommendations.append("â„¹ï¸ Addgene æ— ç°æˆè´¨ç²’ï¼Œéœ€è‡ªè¡Œæ„å»º")
    
    # æ ¹æ®scoreåˆ¤æ–­è¯„çº§
    if score >= 75:
        rating = "âœ… æ¨è"
        suitable = True
    elif score >= 50:
        rating = "âš ï¸ è°¨æ…"
        suitable = True
    else:
        rating = "âŒ ä¸æ¨è"
        suitable = False
    
    return {
        "suitable": suitable,
        "score": score,
        "warnings": warnings,
        "recommendations": recommendations,
        "overall_assessment": rating,
        "cds_length": cds_len
    }
    
    def _search_all_constructs(self, gene_symbol: str, cell_line: Optional[str]) -> Dict:
        """æ£€ç´¢æ‰€æœ‰æ„å»ºæ–¹å¼"""
        results = {}
        
        # ç‰¹å®šç»†èƒç ”ç©¶
        if cell_line:
            articles, count = self.fetcher.search_pubmed_construct(gene_symbol, cell_line=cell_line)
            results["specific_cell"] = {
                "found": count > 0,
                "articles": articles,
                "total_count": count,
                "message": f"æ‰¾åˆ° {count} ç¯‡ç›¸å…³æ–‡çŒ®" if count > 0 else "æ— å®Œå…¨ä¸€è‡´çš„ç»†èƒç³»ç ”ç©¶"
            }
        else:
            results["specific_cell"] = {"found": False, "message": "æœªè¾“å…¥ç»†èƒåç§°"}
        
        # ä¸‰ç§æ„å»ºæ–¹å¼
        for ctype in ["overexpression", "knockdown", "knockout"]:
            articles, count = self.fetcher.search_pubmed_construct(gene_symbol, construct_type=ctype)
            results[ctype] = {
                "articles": articles[:10],
                "total_count": count,
                "methods_summary": self._extract_methods_summary(articles)
            }
        
        return results
    
    def _extract_methods_summary(self, articles: List[Dict]) -> List[str]:
        """æå–å¸¸ç”¨æ–¹æ³•"""
        all_methods = []
        for art in articles:
            methods = art.get("methods", "")
            if methods:
                all_methods.extend([m.strip() for m in methods.split(",")])
        
        from collections import Counter
        method_counts = Counter(all_methods)
        return [f"{k} ({v})" for k, v in method_counts.most_common(3)]
    
    def _format_database_record(self, gene, species, cell_line, ncbi, uniprot, 
                               lentiviral, literature, addgene_data, antibody_data) -> Dict:
        """ç”Ÿæˆæ•°æ®åº“è®°å½•"""
        plasmid_summary = ""
        if addgene_data:
            plasmid_list = [f"{p['plasmid_id']}({p.get('expression_system', 'N/A')})" 
                           for p in addgene_data[:3]]
            plasmid_summary = "; ".join(plasmid_list)
        
        antibody_summary = ""
        if antibody_data:
            ab_list = [f"{ab['antibody_id']}({ab.get('applications', 'N/A')})" 
                      for ab in antibody_data[:3]]
            antibody_summary = "; ".join(ab_list)
        
        return {
            "åŸºå› å": gene,
            "ç‰©ç§": species,
            "ç»†èƒç³»": cell_line or "NA",
            "NCBI_Gene_ID": ncbi.get("gene_id", "NA"),
            "UniProt_ID": uniprot.get("uniprot_id", "NA"),
            "CDSé•¿åº¦": uniprot.get("cds_length_bp", 0),
            "åŸºå› å¿…éœ€æ€§": ncbi.get("phenotype", "æœªçŸ¥"),
            "è›‹ç™½å®šä½": uniprot.get("subcellular_location", "æœªçŸ¥"),
            "æ…¢ç—…æ¯’é€‚ç”¨æ€§": lentiviral.get("overall_assessment", "æœªçŸ¥"),
            "Addgeneè´¨ç²’æ•°": len(addgene_data),
            "Addgeneè´¨ç²’è¯¦æƒ…": plasmid_summary,
            "å¯ç”¨æŠ—ä½“æ•°": len(antibody_data),
            "æŠ—ä½“è¯¦æƒ…": antibody_summary,
            "è¿‡è¡¨è¾¾æ–‡çŒ®æ•°": literature.get("overexpression", {}).get("total_count", 0),
            "æ•²ä½æ–‡çŒ®æ•°": literature.get("knockdown", {}).get("total_count", 0),
            "æ•²é™¤æ–‡çŒ®æ•°": literature.get("knockout", {}).get("total_count", 0),
            "ç‰¹å®šç»†èƒæ–‡çŒ®": "æœ‰" if literature.get("specific_cell", {}).get("found") else "æ— ",
            "æ£€ç´¢æ—¥æœŸ": datetime.now().strftime("%Y-%m-%d")
        }


# ==================== Streamlit ç•Œé¢ ====================

def main():
    st.title("ğŸ”¬ ç»†èƒç³»æ„å»ºæ™ºèƒ½è¯„ä¼°ç³»ç»Ÿ")
    st.markdown("æ•´åˆ NCBI Gene | UniProt | Addgene | Human Protein Atlas")
    
    analyzer = ConstructAnalyzer()
    
    # ==================== ç¬¬ä¸€æ¨¡å—ï¼šç”¨æˆ·è¾“å…¥ ====================
    with st.sidebar:
        st.header("ğŸ“ ç¬¬ä¸€æ¨¡å—ï¼šè¾“å…¥å‚æ•°")
        
        with st.form("input_form"):
            st.subheader("åŸºå› ä¿¡æ¯ï¼ˆå¿…å¡«ï¼‰")
            gene_symbol = st.text_input("åŸºå› åï¼ˆå¦‚ TP53ï¼‰", "").strip().upper()
            species = st.selectbox("åŸºå› ç‰©ç§", 
                                 ["Homo sapiens", "Mus musculus", "Rattus norvegicus"],
                                 index=0)
            
            st.subheader("ç»†èƒä¿¡æ¯ï¼ˆå¯é€‰ï¼‰")
            cell_line = st.text_input("ç»†èƒç³»åç§°ï¼ˆå¦‚ HEK293Tï¼‰", "").strip()
            cell_species = st.selectbox("ç»†èƒç‰©ç§", 
                                       ["æœªæŒ‡å®š", "Homo sapiens", "Mus musculus"], 
                                       index=0)
            
            submitted = st.form_submit_button("ğŸ” å¼€å§‹åˆ†æ", use_container_width=True)
    
    # ==================== åˆ†ææ‰§è¡Œ ====================
    if submitted:
        if not gene_symbol:
            st.error("è¯·è¾“å…¥åŸºå› å")
            return
        
        result = analyzer.analyze_gene(
            gene_symbol, species, 
            cell_line if cell_line else None,
            cell_species if cell_species != "æœªæŒ‡å®š" else None
        )
        
        st.session_state.analysis_results = result
        st.session_state.search_history.append(result["database_record"])
        
        st.success("âœ… åˆ†æå®Œæˆï¼")
        st.balloons()
    
    # ==================== å±•ç¤ºç»“æœ ====================
    if st.session_state.analysis_results:
        result = st.session_state.analysis_results
        
        # åŸºç¡€ä¿¡æ¯
        st.divider()
        cols = st.columns(4)
        cols[0].metric("åŸºå› ", result["input_info"]["gene_symbol"])
        cols[1].metric("ç‰©ç§", result["input_info"]["species"])
        cols[2].metric("ç»†èƒç³»", result["input_info"]["cell_line"])
        cols[3].metric("åˆ†ææ—¶é—´", result["input_info"]["analysis_date"])
        
        # ==================== ç¬¬äºŒæ¨¡å—ï¼šåŸºå› ä¸è›‹ç™½åŠŸèƒ½ ====================
        st.divider()
        st.header("ğŸ§¬ ç¬¬äºŒæ¨¡å—ï¼šåŸºå› åŠŸèƒ½ä¸è›‹ç™½åŠŸèƒ½")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.subheader("åŸºå› åŠŸèƒ½è¯„ä¼°")
            gene_data = result["gene_function"]
            
            if gene_data.get("status") == "success":
                st.markdown(f"**NCBI Gene ID:** {gene_data['gene_id']}")
                st.markdown(f"**æŸ“è‰²ä½“:** {gene_data['chromosome']}")
                
                phenotype = gene_data.get("phenotype", "æœªçŸ¥")
                if "å¿…éœ€" in phenotype:
                    st.error(f"âš ï¸ **è‡´æ­»æ€§:** {phenotype}")
                    st.warning("å»ºè®®ï¼šä½¿ç”¨è¯±å¯¼å‹è¡¨è¾¾ç³»ç»Ÿ")
                else:
                    st.success(f"âœ… **è‡´æ­»æ€§:** {phenotype}")
                
                with st.expander("æŸ¥çœ‹åŸºå› åŠŸèƒ½æè¿°"):
                    st.info(gene_data.get("description", "æ— æè¿°"))
            else:
                st.error(gene_data.get("error"))
            
            st.subheader("Addgene è´¨ç²’èµ„æº")
            plasmids = result["addgene_plasmids"]
            if plasmids:
                for p in plasmids:
                    tag_info = f" [{p.get('tag', '')}]" if p.get('tag') else ""
                    expr_info = f" ({p.get('expression_system', 'N/A')})"
                    st.markdown(f"â€¢ [{p['plasmid_id']}]({p['url']}): {p['name'][:50]}{expr_info}{tag_info}")
            else:
                st.info("æœªåœ¨ Addgene æ‰¾åˆ°ç›¸å…³è´¨ç²’")
        
        with col2:
            st.subheader("è›‹ç™½ä¿¡æ¯ï¼ˆUniProtï¼‰")
            prot_data = result["protein_data"]
            
            if prot_data.get("status") == "success":
                st.markdown(f"**UniProt ID:** {prot_data['uniprot_id']}")
                st.markdown(f"**è›‹ç™½é•¿åº¦:** {prot_data['protein_length']} aa")
                st.markdown(f"**CDSé•¿åº¦:** {prot_data['cds_length_bp']} bp")
                st.markdown("**äºšç»†èƒå®šä½:**")
                st.info(prot_data.get("subcellular_location", "æœªæ ‡æ³¨"))
            else:
                st.error(prot_data.get("error", "æŸ¥è¯¢å¤±è´¥"))
            
            st.subheader("æ…¢ç—…æ¯’åŒ…è£…è¯„ä¼°")
            lentiviral = result["lentiviral_assessment"]
            
            if lentiviral["suitable"]:
                st.success(lentiviral["overall_assessment"])
            else:
                st.error(lentiviral["overall_assessment"])
            
            for w in lentiviral.get("warnings", []):
                st.warning(w)
            for r in lentiviral.get("recommendations", []):
                st.info(r)
        
        # æŠ—ä½“è¡¨æ ¼
        if result["antibodies"]:
            st.subheader("ç»éªŒè¯æŠ—ä½“æ¨èï¼ˆHuman Protein Atlasï¼‰")
            ab_df = pd.DataFrame(result["antibodies"])
            st.dataframe(ab_df[['antibody_id', 'applications', 'reliability', 'vendor', 'link']], 
                        use_container_width=True)
        
        # ==================== ç¬¬ä¸‰æ¨¡å—ï¼šç»†èƒç³»æ„å»º ====================
        st.divider()
        st.header("ğŸ§« ç¬¬ä¸‰æ¨¡å—ï¼šç»†èƒç³»æ„å»ºæ–‡çŒ®")
        
        lit_data = result["cell_line_constructs"]
        
        st.subheader("ç‰¹å®šç»†èƒç³»ç ”ç©¶")
        specific = lit_data["specific_cell"]
        if specific.get("found"):
            st.success(f"âœ… {specific['message']}")
            if specific.get("articles"):
                df_specific = pd.DataFrame(specific["articles"])
                st.dataframe(df_specific[['pmid', 'title', 'methods']], use_container_width=True)
        else:
            st.info(specific.get("message", "æ— å®Œå…¨ä¸€è‡´çš„ç ”ç©¶"))
        
        tabs = st.tabs(["è¿‡è¡¨è¾¾ (Overexpression)", "æ•²ä½ (Knockdown)", "æ•²é™¤ (Knockout)"])
        construct_types = ["overexpression", "knockdown", "knockout"]
        
        for tab, ctype in zip(tabs, construct_types):
            with tab:
                data = lit_data[ctype]
                total = data.get("total_count", 0)
                st.markdown(f"**æ€»æ–‡çŒ®æ•°:** {total} ç¯‡")
                
                if data.get("methods_summary"):
                    st.markdown(f"**å¸¸ç”¨æ–¹æ³•:** {', '.join(data['methods_summary'])}")
                
                if data.get("articles"):
                    for article in data["articles"]:
                        with st.expander(f"{article['pmid']}: {article['title'][:60]}..."):
                            st.markdown(f"**æ–¹æ³•:** {article['methods']}")
                            st.markdown(f"**æ‘˜è¦:** {article['abstract_snippet']}")
                            st.markdown(f"[PubMedé“¾æ¥](https://pubmed.ncbi.nlm.nih.gov/{article['pmid']}/)")
                else:
                    st.info("æœªæ‰¾åˆ°ç›¸å…³æ–‡çŒ®")
        
        # ==================== ç¬¬å››æ¨¡å—ï¼šæ•°æ®åº“ ====================
        st.divider()
        st.header("ğŸ—„ï¸ ç¬¬å››æ¨¡å—ï¼šæ•°æ®åº“æ•´ç†")
        
        if st.session_state.search_history:
            db_df = pd.DataFrame(st.session_state.search_history)
            st.dataframe(db_df, use_container_width=True)
            
            col1, col2 = st.columns(2)
            with col1:
                csv = db_df.to_csv(index=False).encode('utf-8')
                st.download_button("ğŸ“¥ å¯¼å‡º CSV æ•°æ®åº“", csv,
                                f"cell_line_db_{datetime.now().strftime('%Y%m%d')}.csv", "text/csv")
            with col2:
                json_str = json.dumps(st.session_state.search_history, ensure_ascii=False, indent=2)
                st.download_button("ğŸ“¥ å¯¼å‡º JSON", json_str,
                                f"db_{datetime.now().strftime('%Y%m%d')}.json", "application/json")
            
            if st.button("ğŸ—‘ï¸ æ¸…ç©ºå½“å‰ä¼šè¯è®°å½•"):
                st.session_state.search_history = []
                st.rerun()

if __name__ == "__main__":

    main()

